2024-06-01 20:45:46,364 - root - INFO - N_EPOCH: 50
2024-06-01 20:45:46,365 - root - INFO - LEARNING_RATE: 8e-05
2024-06-01 20:45:46,366 - root - INFO - HIDDEN_LAYER: 28
2024-06-01 20:45:46,366 - root - INFO - HIDDEN_WIDTH: 128
2024-06-01 20:45:46,366 - root - INFO - EXPERIMENT_NAME: exp_put_10_gen
2024-06-01 20:45:46,366 - root - INFO - Model type: AmericanPut_gated3
2024-06-01 20:45:47,599 - root - INFO - train set size: (8000, 9)
2024-06-01 20:45:47,600 - root - INFO - test set size: (2000, 9)
2024-06-01 20:45:47,601 - root - INFO - Initial MSE train: 636.6559, Initial MSE val: 613.5619
2024-06-01 20:45:49,172 - root - INFO - Total number of learnable parameters: 463373
2024-06-01 20:45:50,086 - root - INFO - Optimizer: RMSprop
2024-06-01 20:45:52,846 - root - INFO - Epoch 1, train loss: 296.3920, val loss: 287.3775
2024-06-01 20:45:55,704 - root - INFO - Epoch 2, train loss: 286.1608, val loss: 288.5585
2024-06-01 20:45:58,570 - root - INFO - Epoch 3, train loss: 286.4500, val loss: 286.7316
2024-06-01 20:46:01,202 - root - INFO - Epoch 4, train loss: 286.3061, val loss: 282.0581
2024-06-01 20:46:03,821 - root - INFO - Epoch 5, train loss: 285.8744, val loss: 284.3857
2024-06-01 20:46:06,457 - root - INFO - Epoch 6, train loss: 285.2371, val loss: 283.2864
2024-06-01 20:46:09,257 - root - INFO - Epoch 7, train loss: 285.7056, val loss: 284.5220
2024-06-01 20:46:12,163 - root - INFO - Epoch 8, train loss: 285.5517, val loss: 284.7376
2024-06-01 20:46:14,805 - root - INFO - Epoch 9, train loss: 284.4569, val loss: 285.1309
2024-06-01 20:46:17,521 - root - INFO - Epoch 10, train loss: 285.4274, val loss: 285.7804
2024-06-01 20:46:20,128 - root - INFO - Epoch 11, train loss: 285.1172, val loss: 284.2090
2024-06-01 20:46:22,742 - root - INFO - Epoch 12, train loss: 285.2431, val loss: 283.7445
2024-06-01 20:46:25,350 - root - INFO - Epoch 13, train loss: 284.7354, val loss: 283.9046
2024-06-01 20:46:27,881 - root - INFO - Epoch 14, train loss: 284.4495, val loss: 284.6602
2024-06-01 20:46:30,438 - root - INFO - Epoch 15, train loss: 284.7138, val loss: 283.0985
2024-06-01 20:46:33,141 - root - INFO - Epoch 16, train loss: 284.6518, val loss: 283.4829
2024-06-01 20:46:35,684 - root - INFO - Epoch 17, train loss: 284.3187, val loss: 287.2188
2024-06-01 20:46:38,249 - root - INFO - Epoch 18, train loss: 284.5894, val loss: 283.9859
2024-06-01 20:46:40,874 - root - INFO - Epoch 19, train loss: 284.7243, val loss: 284.1778
2024-06-01 20:46:43,398 - root - INFO - Epoch 20, train loss: 284.1900, val loss: 283.7112
2024-06-01 20:46:46,061 - root - INFO - Epoch 21, train loss: 284.1132, val loss: 285.5307
2024-06-01 20:46:48,586 - root - INFO - Epoch 22, train loss: 284.1733, val loss: 284.3941
2024-06-01 20:46:51,114 - root - INFO - Epoch 23, train loss: 284.1034, val loss: 284.1270
2024-06-01 20:46:53,690 - root - INFO - Epoch 24, train loss: 283.7132, val loss: 283.5032
2024-06-01 20:46:56,230 - root - INFO - Epoch 25, train loss: 283.5927, val loss: 282.8844
2024-06-01 20:46:58,695 - root - INFO - Epoch 26, train loss: 283.8695, val loss: 283.1343
2024-06-01 20:47:01,274 - root - INFO - Epoch 27, train loss: 283.6188, val loss: 283.4257
2024-06-01 20:47:03,922 - root - INFO - Epoch 28, train loss: 283.9069, val loss: 282.8028
2024-06-01 20:47:06,480 - root - INFO - Epoch 29, train loss: 283.3519, val loss: 282.9074
2024-06-01 20:47:08,990 - root - INFO - Epoch 30, train loss: 283.4861, val loss: 284.2494
2024-06-01 20:47:11,563 - root - INFO - Epoch 31, train loss: 283.4162, val loss: 284.1725
2024-06-01 20:47:14,161 - root - INFO - Epoch 32, train loss: 283.9792, val loss: 283.1567
2024-06-01 20:47:16,730 - root - INFO - Epoch 33, train loss: 283.3526, val loss: 283.5946
2024-06-01 20:47:19,249 - root - INFO - Epoch 34, train loss: 283.2888, val loss: 282.9632
2024-06-01 20:47:21,903 - root - INFO - Epoch 35, train loss: 282.7674, val loss: 283.9859
2024-06-01 20:47:24,481 - root - INFO - Epoch 36, train loss: 283.0972, val loss: 283.5809
2024-06-01 20:47:27,025 - root - INFO - Epoch 37, train loss: 283.1465, val loss: 283.6377
2024-06-01 20:47:29,514 - root - INFO - Epoch 38, train loss: 283.1486, val loss: 283.7087
2024-06-01 20:47:32,104 - root - INFO - Epoch 39, train loss: 283.1171, val loss: 283.1224
2024-06-01 20:47:34,657 - root - INFO - Epoch 40, train loss: 283.1108, val loss: 283.1898
2024-06-01 20:47:37,314 - root - INFO - Epoch 41, train loss: 282.9919, val loss: 282.9189
2024-06-01 20:47:39,874 - root - INFO - Epoch 42, train loss: 282.6431, val loss: 283.1038
2024-06-01 20:47:42,435 - root - INFO - Epoch 43, train loss: 282.7517, val loss: 283.7464
2024-06-01 20:47:45,051 - root - INFO - Epoch 44, train loss: 282.4168, val loss: 283.1638
2024-06-01 20:47:47,640 - root - INFO - Epoch 45, train loss: 282.3893, val loss: 283.4889
2024-06-01 20:47:50,212 - root - INFO - Epoch 46, train loss: 282.4067, val loss: 283.0451
2024-06-01 20:47:52,843 - root - INFO - Epoch 47, train loss: 282.2625, val loss: 283.3341
2024-06-01 20:47:55,434 - root - INFO - Epoch 48, train loss: 282.0584, val loss: 283.5653
2024-06-01 20:47:57,966 - root - INFO - Epoch 49, train loss: 282.0992, val loss: 283.2435
2024-06-01 20:48:00,564 - root - INFO - Epoch 50, train loss: 282.0449, val loss: 283.2548
2024-06-01 20:50:14,197 - root - INFO - % of variation before training: 223.67
2024-06-01 20:50:14,198 - root - INFO - % of variation after training: 99.3
2024-06-01 20:50:14,198 - root - INFO - % of variation before training: 217.19
2024-06-01 20:50:14,199 - root - INFO - % of variation after training: 100.22
:45:46,366 - root - INFO - Model type: AmericanPut_gated3
2024-06-01 20:45:47,599 - root - INFO - train set size: (8000, 9)
2024-06-01 20:45:47,600 - root - INFO - test set size: (2000, 9)
2024-06-01 20:45:47,601 - root - INFO - Initial MSE train: 636.6559, Initial MSE val: 613.5619
2024-06-01 20:45:49,172 - root - INFO - Total number of learnable parameters: 463373
2024-06-01 20:45:50,086 - root - INFO - Optimizer: RMSprop
2024-06-01 20:45:52,846 - root - INFO - Epoch 1, train loss: 296.3920, val loss: 287.3775
2024-06-01 20:45:55,704 - root - INFO - Epoch 2, train loss: 286.1608, val loss: 288.5585
2024-06-01 20:45:58,570 - root - INFO - Epoch 3, train loss: 286.4500, val loss: 286.7316
2024-06-01 20:46:01,202 - root - INFO - Epoch 4, train loss: 286.3061, val loss: 282.0581
2024-06-01 20:46:03,821 - root - INFO - Epoch 5, train loss: 285.8744, val loss: 284.3857
2024-06-01 20:46:06,457 - root - INFO - Epoch 6, train loss: 285.2371, val loss: 283.2864
2024-06-01 20:46:09,257 - root - INFO - Epoch 7, train loss: 285.7056, val loss: 284.5220
2024-06-01 20:46:12,163 - root - INFO - Epoch 8, train loss: 285.5517, val loss: 284.7376
2024-06-01 20:46:14,805 - root - INFO - Epoch 9, train loss: 284.4569, val loss: 285.1309
2024-06-01 20:46:17,521 - root - INFO - Epoch 10, train loss: 285.4274, val loss: 285.7804
2024-06-01 20:46:20,128 - root - INFO - Epoch 11, train loss: 285.1172, val loss: 284.2090
2024-06-01 20:46:22,742 - root - INFO - Epoch 12, train loss: 285.2431, val loss: 283.7445
2024-06-01 20:46:25,350 - root - INFO - Epoch 13, train loss: 284.7354, val loss: 283.9046
2024-06-01 20:46:27,881 - root - INFO - Epoch 14, train loss: 284.4495, val loss: 284.6602
2024-06-01 20:46:30,438 - root - INFO - Epoch 15, train loss: 284.7138, val loss: 283.0985
2024-06-01 20:46:33,141 - root - INFO - Epoch 16, train loss: 284.6518, val loss: 283.4829
2024-06-01 20:46:35,684 - root - INFO - Epoch 17, train loss: 284.3187, val loss: 287.2188
2024-06-01 20:46:38,249 - root - INFO - Epoch 18, train loss: 284.5894, val loss: 283.9859
2024-06-01 20:46:40,874 - root - INFO - Epoch 19, train loss: 284.7243, val loss: 284.1778
2024-06-01 20:46:43,398 - root - INFO - Epoch 20, train loss: 284.1900, val loss: 283.7112
2024-06-01 20:46:46,061 - root - INFO - Epoch 21, train loss: 284.1132, val loss: 285.5307
2024-06-01 20:46:48,586 - root - INFO - Epoch 22, train loss: 284.1733, val loss: 284.3941
2024-06-01 20:46:51,114 - root - INFO - Epoch 23, train loss: 284.1034, val loss: 284.1270
2024-06-01 20:46:53,690 - root - INFO - Epoch 24, train loss: 283.7132, val loss: 283.5032
2024-06-01 20:46:56,230 - root - INFO - Epoch 25, train loss: 283.5927, val loss: 282.8844
2024-06-01 20:46:58,695 - root - INFO - Epoch 26, train loss: 283.8695, val loss: 283.1343
2024-06-01 20:47:01,274 - root - INFO - Epoch 27, train loss: 283.6188, val loss: 283.4257
2024-06-01 20:47:03,922 - root - INFO - Epoch 28, train loss: 283.9069, val loss: 282.8028
2024-06-01 20:47:06,480 - root - INFO - Epoch 29, train loss: 283.3519, val loss: 282.9074
2024-06-01 20:47:08,990 - root - INFO - Epoch 30, train loss: 283.4861, val loss: 284.2494
2024-06-01 20:47:11,563 - root - INFO - Epoch 31, train loss: 283.4162, val loss: 284.1725
2024-06-01 20:47:14,161 - root - INFO - Epoch 32, train loss: 283.9792, val loss: 283.1567
2024-06-01 20:47:16,730 - root - INFO - Epoch 33, train loss: 283.3526, val loss: 283.5946
2024-06-01 20:47:19,249 - root - INFO - Epoch 34, train loss: 283.2888, val loss: 282.9632
2024-06-01 20:47:21,903 - root - INFO - Epoch 35, train loss: 282.7674, val loss: 283.9859
2024-06-01 20:47:24,481 - root - INFO - Epoch 36, train loss: 283.0972, val loss: 283.5809
2024-06-01 20:47:27,025 - root - INFO - Epoch 37, train loss: 283.1465, val loss: 283.6377
2024-06-01 20:47:29,514 - root - INFO - Epoch 38, train loss: 283.1486, val loss: 283.7087
2024-06-01 20:47:32,104 - root - INFO - Epoch 39, train loss: 283.1171, val loss: 283.1224
2024-06-01 20:47:34,657 - root - INFO - Epoch 40, train loss: 283.1108, val loss: 283.1898
2024-06-01 20:47:37,314 - root - INFO - Epoch 41, train loss: 282.9919, val loss: 282.9189
2024-06-01 20:47:39,874 - root - INFO - Epoch 42, train loss: 282.6431, val loss: 283.1038
2024-06-01 20:47:42,435 - root - INFO - Epoch 43, train loss: 282.7517, val loss: 283.7464
2024-06-01 20:47:45,051 - root - INFO - Epoch 44, train loss: 282.4168, val loss: 283.1638
2024-06-01 20:47:47,640 - root - INFO - Epoch 45, train loss: 282.3893, val loss: 283.4889
2024-06-01 20:47:50,212 - root - INFO - Epoch 46, train loss: 282.4067, val loss: 283.0451
2024-06-01 20:47:52,843 - root - INFO - Epoch 47, train loss: 282.2625, val loss: 283.3341
2024-06-01 20:47:55,434 - root - INFO - Epoch 48, train loss: 282.0584, val loss: 283.5653
2024-06-01 20:47:57,966 - root - INFO - Epoch 49, train loss: 282.0992, val loss: 283.2435
2024-06-01 20:48:00,564 - root - INFO - Epoch 50, train loss: 282.0449, val loss: 283.2548
2024-06-01 20:50:14,197 - root - INFO - % of variation before training: 223.67
2024-06-01 20:50:14,198 - root - INFO - % of variation after training: 99.3
2024-06-01 20:50:14,198 - root - INFO - % of variation before training: 217.19
2024-06-01 20:50:14,199 - root - INFO - % of variation after training: 100.22
0:45:46,366 - root - INFO - Model type: AmericanPut_gated3
2024-06-01 20:45:47,599 - root - INFO - train set size: (8000, 9)
2024-06-01 20:45:47,600 - root - INFO - test set size: (2000, 9)
2024-06-01 20:45:47,601 - root - INFO - Initial MSE train: 636.6559, Initial MSE val: 613.5619
2024-06-01 20:45:49,172 - root - INFO - Total number of learnable parameters: 463373
2024-06-01 20:45:50,086 - root - INFO - Optimizer: RMSprop
2024-06-01 20:45:52,846 - root - INFO - Epoch 1, train loss: 296.3920, val loss: 287.3775
2024-06-01 20:45:55,704 - root - INFO - Epoch 2, train loss: 286.1608, val loss: 288.5585
2024-06-01 20:45:58,570 - root - INFO - Epoch 3, train loss: 286.4500, val loss: 286.7316
2024-06-01 20:46:01,202 - root - INFO - Epoch 4, train loss: 286.3061, val loss: 282.0581
2024-06-01 20:46:03,821 - root - INFO - Epoch 5, train loss: 285.8744, val loss: 284.3857
2024-06-01 20:46:06,457 - root - INFO - Epoch 6, train loss: 285.2371, val loss: 283.2864
2024-06-01 20:46:09,257 - root - INFO - Epoch 7, train loss: 285.7056, val loss: 284.5220
2024-06-01 20:46:12,163 - root - INFO - Epoch 8, train loss: 285.5517, val loss: 284.7376
2024-06-01 20:46:14,805 - root - INFO - Epoch 9, train loss: 284.4569, val loss: 285.1309
2024-06-01 20:46:17,521 - root - INFO - Epoch 10, train loss: 285.4274, val loss: 285.7804
2024-06-01 20:46:20,128 - root - INFO - Epoch 11, train loss: 285.1172, val loss: 284.2090
2024-06-01 20:46:22,742 - root - INFO - Epoch 12, train loss: 285.2431, val loss: 283.7445
2024-06-01 20:46:25,350 - root - INFO - Epoch 13, train loss: 284.7354, val loss: 283.9046
2024-06-01 20:46:27,881 - root - INFO - Epoch 14, train loss: 284.4495, val loss: 284.6602
2024-06-01 20:46:30,438 - root - INFO - Epoch 15, train loss: 284.7138, val loss: 283.0985
2024-06-01 20:46:33,141 - root - INFO - Epoch 16, train loss: 284.6518, val loss: 283.4829
2024-06-01 20:46:35,684 - root - INFO - Epoch 17, train loss: 284.3187, val loss: 287.2188
2024-06-01 20:46:38,249 - root - INFO - Epoch 18, train loss: 284.5894, val loss: 283.9859
2024-06-01 20:46:40,874 - root - INFO - Epoch 19, train loss: 284.7243, val loss: 284.1778
2024-06-01 20:46:43,398 - root - INFO - Epoch 20, train loss: 284.1900, val loss: 283.7112
2024-06-01 20:46:46,061 - root - INFO - Epoch 21, train loss: 284.1132, val loss: 285.5307
2024-06-01 20:46:48,586 - root - INFO - Epoch 22, train loss: 284.1733, val loss: 284.3941
2024-06-01 20:46:51,114 - root - INFO - Epoch 23, train loss: 284.1034, val loss: 284.1270
2024-06-01 20:46:53,690 - root - INFO - Epoch 24, train loss: 283.7132, val loss: 283.5032
2024-06-01 20:46:56,230 - root - INFO - Epoch 25, train loss: 283.5927, val loss: 282.8844
2024-06-01 20:46:58,695 - root - INFO - Epoch 26, train loss: 283.8695, val loss: 283.1343
2024-06-01 20:47:01,274 - root - INFO - Epoch 27, train loss: 283.6188, val loss: 283.4257
2024-06-01 20:47:03,922 - root - INFO - Epoch 28, train loss: 283.9069, val loss: 282.8028
2024-06-01 20:47:06,480 - root - INFO - Epoch 29, train loss: 283.3519, val loss: 282.9074
2024-06-01 20:47:08,990 - root - INFO - Epoch 30, train loss: 283.4861, val loss: 284.2494
2024-06-01 20:47:11,563 - root - INFO - Epoch 31, train loss: 283.4162, val loss: 284.1725
2024-06-01 20:47:14,161 - root - INFO - Epoch 32, train loss: 283.9792, val loss: 283.1567
2024-06-01 20:47:16,730 - root - INFO - Epoch 33, train loss: 283.3526, val loss: 283.5946
2024-06-01 20:47:19,249 - root - INFO - Epoch 34, train loss: 283.2888, val loss: 282.9632
2024-06-01 20:47:21,903 - root - INFO - Epoch 35, train loss: 282.7674, val loss: 283.9859
2024-06-01 20:47:24,481 - root - INFO - Epoch 36, train loss: 283.0972, val loss: 283.5809
2024-06-01 20:47:27,025 - root - INFO - Epoch 37, train loss: 283.1465, val loss: 283.6377
2024-06-01 20:47:29,514 - root - INFO - Epoch 38, train loss: 283.1486, val loss: 283.7087
2024-06-01 20:47:32,104 - root - INFO - Epoch 39, train loss: 283.1171, val loss: 283.1224
2024-06-01 20:47:34,657 - root - INFO - Epoch 40, train loss: 283.1108, val loss: 283.1898
2024-06-01 20:47:37,314 - root - INFO - Epoch 41, train loss: 282.9919, val loss: 282.9189
2024-06-01 20:47:39,874 - root - INFO - Epoch 42, train loss: 282.6431, val loss: 283.1038
2024-06-01 20:47:42,435 - root - INFO - Epoch 43, train loss: 282.7517, val loss: 283.7464
2024-06-01 20:47:45,051 - root - INFO - Epoch 44, train loss: 282.4168, val loss: 283.1638
2024-06-01 20:47:47,640 - root - INFO - Epoch 45, train loss: 282.3893, val loss: 283.4889
2024-06-01 20:47:50,212 - root - INFO - Epoch 46, train loss: 282.4067, val loss: 283.0451
2024-06-01 20:47:52,843 - root - INFO - Epoch 47, train loss: 282.2625, val loss: 283.3341
2024-06-01 20:47:55,434 - root - INFO - Epoch 48, train loss: 282.0584, val loss: 283.5653
2024-06-01 20:47:57,966 - root - INFO - Epoch 49, train loss: 282.0992, val loss: 283.2435
2024-06-01 20:48:00,564 - root - INFO - Epoch 50, train loss: 282.0449, val loss: 283.2548
2024-06-01 20:50:14,197 - root - INFO - % of variation before training: 223.67
2024-06-01 20:50:14,198 - root - INFO - % of variation after training: 99.3
2024-06-01 20:50:14,198 - root - INFO - % of variation before training: 217.19
2024-06-01 20:50:14,199 - root - INFO - % of variation after training: 100.22
0:45:46,366 - root - INFO - Model type: AmericanPut_gated3
2024-06-01 20:45:47,599 - root - INFO - train set size: (8000, 9)
2024-06-01 20:45:47,600 - root - INFO - test set size: (2000, 9)
2024-06-01 20:45:47,601 - root - INFO - Initial MSE train: 636.6559, Initial MSE val: 613.5619
2024-06-01 20:45:49,172 - root - INFO - Total number of learnable parameters: 463373
2024-06-01 20:45:50,086 - root - INFO - Optimizer: RMSprop
2024-06-01 20:45:52,846 - root - INFO - Epoch 1, train loss: 296.3920, val loss: 287.3775
2024-06-01 20:45:55,704 - root - INFO - Epoch 2, train loss: 286.1608, val loss: 288.5585
2024-06-01 20:45:58,570 - root - INFO - Epoch 3, train loss: 286.4500, val loss: 286.7316
2024-06-01 20:46:01,202 - root - INFO - Epoch 4, train loss: 286.3061, val loss: 282.0581
2024-06-01 20:46:03,821 - root - INFO - Epoch 5, train loss: 285.8744, val loss: 284.3857
2024-06-01 20:46:06,457 - root - INFO - Epoch 6, train loss: 285.2371, val loss: 283.2864
2024-06-01 20:46:09,257 - root - INFO - Epoch 7, train loss: 285.7056, val loss: 284.5220
2024-06-01 20:46:12,163 - root - INFO - Epoch 8, train loss: 285.5517, val loss: 284.7376
2024-06-01 20:46:14,805 - root - INFO - Epoch 9, train loss: 284.4569, val loss: 285.1309
2024-06-01 20:46:17,521 - root - INFO - Epoch 10, train loss: 285.4274, val loss: 285.7804
2024-06-01 20:46:20,128 - root - INFO - Epoch 11, train loss: 285.1172, val loss: 284.2090
2024-06-01 20:46:22,742 - root - INFO - Epoch 12, train loss: 285.2431, val loss: 283.7445
2024-06-01 20:46:25,350 - root - INFO - Epoch 13, train loss: 284.7354, val loss: 283.9046
2024-06-01 20:46:27,881 - root - INFO - Epoch 14, train loss: 284.4495, val loss: 284.6602
2024-06-01 20:46:30,438 - root - INFO - Epoch 15, train loss: 284.7138, val loss: 283.0985
2024-06-01 20:46:33,141 - root - INFO - Epoch 16, train loss: 284.6518, val loss: 283.4829
2024-06-01 20:46:35,684 - root - INFO - Epoch 17, train loss: 284.3187, val loss: 287.2188
2024-06-01 20:46:38,249 - root - INFO - Epoch 18, train loss: 284.5894, val loss: 283.9859
2024-06-01 20:46:40,874 - root - INFO - Epoch 19, train loss: 284.7243, val loss: 284.1778
2024-06-01 20:46:43,398 - root - INFO - Epoch 20, train loss: 284.1900, val loss: 283.7112
2024-06-01 20:46:46,061 - root - INFO - Epoch 21, train loss: 284.1132, val loss: 285.5307
2024-06-01 20:46:48,586 - root - INFO - Epoch 22, train loss: 284.1733, val loss: 284.3941
2024-06-01 20:46:51,114 - root - INFO - Epoch 23, train loss: 284.1034, val loss: 284.1270
2024-06-01 20:46:53,690 - root - INFO - Epoch 24, train loss: 283.7132, val loss: 283.5032
2024-06-01 20:46:56,230 - root - INFO - Epoch 25, train loss: 283.5927, val loss: 282.8844
2024-06-01 20:46:58,695 - root - INFO - Epoch 26, train loss: 283.8695, val loss: 283.1343
2024-06-01 20:47:01,274 - root - INFO - Epoch 27, train loss: 283.6188, val loss: 283.4257
2024-06-01 20:47:03,922 - root - INFO - Epoch 28, train loss: 283.9069, val loss: 282.8028
2024-06-01 20:47:06,480 - root - INFO - Epoch 29, train loss: 283.3519, val loss: 282.9074
2024-06-01 20:47:08,990 - root - INFO - Epoch 30, train loss: 283.4861, val loss: 284.2494
2024-06-01 20:47:11,563 - root - INFO - Epoch 31, train loss: 283.4162, val loss: 284.1725
2024-06-01 20:47:14,161 - root - INFO - Epoch 32, train loss: 283.9792, val loss: 283.1567
2024-06-01 20:47:16,730 - root - INFO - Epoch 33, train loss: 283.3526, val loss: 283.5946
2024-06-01 20:47:19,249 - root - INFO - Epoch 34, train loss: 283.2888, val loss: 282.9632
2024-06-01 20:47:21,903 - root - INFO - Epoch 35, train loss: 282.7674, val loss: 283.9859
2024-06-01 20:47:24,481 - root - INFO - Epoch 36, train loss: 283.0972, val loss: 283.5809
2024-06-01 20:47:27,025 - root - INFO - Epoch 37, train loss: 283.1465, val loss: 283.6377
2024-06-01 20:47:29,514 - root - INFO - Epoch 38, train loss: 283.1486, val loss: 283.7087
2024-06-01 20:47:32,104 - root - INFO - Epoch 39, train loss: 283.1171, val loss: 283.1224
2024-06-01 20:47:34,657 - root - INFO - Epoch 40, train loss: 283.1108, val loss: 283.1898
2024-06-01 20:47:37,314 - root - INFO - Epoch 41, train loss: 282.9919, val loss: 282.9189
2024-06-01 20:47:39,874 - root - INFO - Epoch 42, train loss: 282.6431, val loss: 283.1038
2024-06-01 20:47:42,435 - root - INFO - Epoch 43, train loss: 282.7517, val loss: 283.7464
2024-06-01 20:47:45,051 - root - INFO - Epoch 44, train loss: 282.4168, val loss: 283.1638
2024-06-01 20:47:47,640 - root - INFO - Epoch 45, train loss: 282.3893, val loss: 283.4889
2024-06-01 20:47:50,212 - root - INFO - Epoch 46, train loss: 282.4067, val loss: 283.0451
2024-06-01 20:47:52,843 - root - INFO - Epoch 47, train loss: 282.2625, val loss: 283.3341
2024-06-01 20:47:55,434 - root - INFO - Epoch 48, train loss: 282.0584, val loss: 283.5653
2024-06-01 20:47:57,966 - root - INFO - Epoch 49, train loss: 282.0992, val loss: 283.2435
2024-06-01 20:48:00,564 - root - INFO - Epoch 50, train loss: 282.0449, val loss: 283.2548
2024-06-01 20:50:14,197 - root - INFO - % of variation before training: 223.67
2024-06-01 20:50:14,198 - root - INFO - % of variation after training: 99.3
2024-06-01 20:50:14,198 - root - INFO - % of variation before training: 217.19
2024-06-01 20:50:14,199 - root - INFO - % of variation after training: 100.22
NFO - Epoch 8, train loss: 285.5517, val loss: 284.7376
2024-06-01 20:46:14,805 - root - INFO - Epoch 9, train loss: 284.4569, val loss: 285.1309
2024-06-01 20:46:17,521 - root - INFO - Epoch 10, train loss: 285.4274, val loss: 285.7804
2024-06-01 20:46:20,128 - root - INFO - Epoch 11, train loss: 285.1172, val loss: 284.2090
2024-06-01 20:46:22,742 - root - INFO - Epoch 12, train loss: 285.2431, val loss: 283.7445
2024-06-01 20:46:25,350 - root - INFO - Epoch 13, train loss: 284.7354, val loss: 283.9046
2024-06-01 20:46:27,881 - root - INFO - Epoch 14, train loss: 284.4495, val loss: 284.6602
2024-06-01 20:46:30,438 - root - INFO - Epoch 15, train loss: 284.7138, val loss: 283.0985
2024-06-01 20:46:33,141 - root - INFO - Epoch 16, train loss: 284.6518, val loss: 283.4829
2024-06-01 20:46:35,684 - root - INFO - Epoch 17, train loss: 284.3187, val loss: 287.2188
2024-06-01 20:46:38,249 - root - INFO - Epoch 18, train loss: 284.5894, val loss: 283.9859
2024-06-01 20:46:40,874 - root - INFO - Epoch 19, train loss: 284.7243, val loss: 284.1778
2024-06-01 20:46:43,398 - root - INFO - Epoch 20, train loss: 284.1900, val loss: 283.7112
2024-06-01 20:46:46,061 - root - INFO - Epoch 21, train loss: 284.1132, val loss: 285.5307
2024-06-01 20:46:48,586 - root - INFO - Epoch 22, train loss: 284.1733, val loss: 284.3941
2024-06-01 20:46:51,114 - root - INFO - Epoch 23, train loss: 284.1034, val loss: 284.1270
2024-06-01 20:46:53,690 - root - INFO - Epoch 24, train loss: 283.7132, val loss: 283.5032
2024-06-01 20:46:56,230 - root - INFO - Epoch 25, train loss: 283.5927, val loss: 282.8844
2024-06-01 20:46:58,695 - root - INFO - Epoch 26, train loss: 283.8695, val loss: 283.1343
2024-06-01 20:47:01,274 - root - INFO - Epoch 27, train loss: 283.6188, val loss: 283.4257
2024-06-01 20:47:03,922 - root - INFO - Epoch 28, train loss: 283.9069, val loss: 282.8028
2024-06-01 20:47:06,480 - root - INFO - Epoch 29, train loss: 283.3519, val loss: 282.9074
2024-06-01 20:47:08,990 - root - INFO - Epoch 30, train loss: 283.4861, val loss: 284.2494
2024-06-01 20:47:11,563 - root - INFO - Epoch 31, train loss: 283.4162, val loss: 284.1725
2024-06-01 20:47:14,161 - root - INFO - Epoch 32, train loss: 283.9792, val loss: 283.1567
2024-06-01 20:47:16,730 - root - INFO - Epoch 33, train loss: 283.3526, val loss: 283.5946
2024-06-01 20:47:19,249 - root - INFO - Epoch 34, train loss: 283.2888, val loss: 282.9632
2024-06-01 20:47:21,903 - root - INFO - Epoch 35, train loss: 282.7674, val loss: 283.9859
2024-06-01 20:47:24,481 - root - INFO - Epoch 36, train loss: 283.0972, val loss: 283.5809
2024-06-01 20:47:27,025 - root - INFO - Epoch 37, train loss: 283.1465, val loss: 283.6377
2024-06-01 20:47:29,514 - root - INFO - Epoch 38, train loss: 283.1486, val loss: 283.7087
2024-06-01 20:47:32,104 - root - INFO - Epoch 39, train loss: 283.1171, val loss: 283.1224
2024-06-01 20:47:34,657 - root - INFO - Epoch 40, train loss: 283.1108, val loss: 283.1898
2024-06-01 20:47:37,314 - root - INFO - Epoch 41, train loss: 282.9919, val loss: 282.9189
2024-06-01 20:47:39,874 - root - INFO - Epoch 42, train loss: 282.6431, val loss: 283.1038
2024-06-01 20:47:42,435 - root - INFO - Epoch 43, train loss: 282.7517, val loss: 283.7464
2024-06-01 20:47:45,051 - root - INFO - Epoch 44, train loss: 282.4168, val loss: 283.1638
2024-06-01 20:47:47,640 - root - INFO - Epoch 45, train loss: 282.3893, val loss: 283.4889
2024-06-01 20:47:50,212 - root - INFO - Epoch 46, train loss: 282.4067, val loss: 283.0451
2024-06-01 20:47:52,843 - root - INFO - Epoch 47, train loss: 282.2625, val loss: 283.3341
2024-06-01 20:47:55,434 - root - INFO - Epoch 48, train loss: 282.0584, val loss: 283.5653
2024-06-01 20:47:57,966 - root - INFO - Epoch 49, train loss: 282.0992, val loss: 283.2435
2024-06-01 20:48:00,564 - root - INFO - Epoch 50, train loss: 282.0449, val loss: 283.2548
2024-06-01 20:50:14,197 - root - INFO - % of variation before training: 223.67
2024-06-01 20:50:14,198 - root - INFO - % of variation after training: 99.3
2024-06-01 20:50:14,198 - root - INFO - % of variation before training: 217.19
2024-06-01 20:50:14,199 - root - INFO - % of variation after training: 100.22
:45:46,366 - root - INFO - Model type: AmericanPut_gated3
2024-06-01 20:45:47,599 - root - INFO - train set size: (8000, 9)
2024-06-01 20:45:47,600 - root - INFO - test set size: (2000, 9)
2024-06-01 20:45:47,601 - root - INFO - Initial MSE train: 636.6559, Initial MSE val: 613.5619
2024-06-01 20:45:49,172 - root - INFO - Total number of learnable parameters: 463373
2024-06-01 20:45:50,086 - root - INFO - Optimizer: RMSprop
2024-06-01 20:45:52,846 - root - INFO - Epoch 1, train loss: 296.3920, val loss: 287.3775
2024-06-01 20:45:55,704 - root - INFO - Epoch 2, train loss: 286.1608, val loss: 288.5585
2024-06-01 20:45:58,570 - root - INFO - Epoch 3, train loss: 286.4500, val loss: 286.7316
2024-06-01 20:46:01,202 - root - INFO - Epoch 4, train loss: 286.3061, val loss: 282.0581
2024-06-01 20:46:03,821 - root - INFO - Epoch 5, train loss: 285.8744, val loss: 284.3857
2024-06-01 20:46:06,457 - root - INFO - Epoch 6, train loss: 285.2371, val loss: 283.2864
2024-06-01 20:46:09,257 - root - INFO - Epoch 7, train loss: 285.7056, val loss: 284.5220
2024-06-01 20:46:12,163 - root - INFO - Epoch 8, train loss: 285.5517, val loss: 284.7376
2024-06-01 20:46:14,805 - root - INFO - Epoch 9, train loss: 284.4569, val loss: 285.1309
2024-06-01 20:46:17,521 - root - INFO - Epoch 10, train loss: 285.4274, val loss: 285.7804
2024-06-01 20:46:20,128 - root - INFO - Epoch 11, train loss: 285.1172, val loss: 284.2090
2024-06-01 20:46:22,742 - root - INFO - Epoch 12, train loss: 285.2431, val loss: 283.7445
2024-06-01 20:46:25,350 - root - INFO - Epoch 13, train loss: 284.7354, val loss: 283.9046
2024-06-01 20:46:27,881 - root - INFO - Epoch 14, train loss: 284.4495, val loss: 284.6602
2024-06-01 20:46:30,438 - root - INFO - Epoch 15, train loss: 284.7138, val loss: 283.0985
2024-06-01 20:46:33,141 - root - INFO - Epoch 16, train loss: 284.6518, val loss: 283.4829
2024-06-01 20:46:35,684 - root - INFO - Epoch 17, train loss: 284.3187, val loss: 287.2188
2024-06-01 20:46:38,249 - root - INFO - Epoch 18, train loss: 284.5894, val loss: 283.9859
2024-06-01 20:46:40,874 - root - INFO - Epoch 19, train loss: 284.7243, val loss: 284.1778
2024-06-01 20:46:43,398 - root - INFO - Epoch 20, train loss: 284.1900, val loss: 283.7112
2024-06-01 20:46:46,061 - root - INFO - Epoch 21, train loss: 284.1132, val loss: 285.5307
2024-06-01 20:46:48,586 - root - INFO - Epoch 22, train loss: 284.1733, val loss: 284.3941
2024-06-01 20:46:51,114 - root - INFO - Epoch 23, train loss: 284.1034, val loss: 284.1270
2024-06-01 20:46:53,690 - root - INFO - Epoch 24, train loss: 283.7132, val loss: 283.5032
2024-06-01 20:46:56,230 - root - INFO - Epoch 25, train loss: 283.5927, val loss: 282.8844
2024-06-01 20:46:58,695 - root - INFO - Epoch 26, train loss: 283.8695, val loss: 283.1343
2024-06-01 20:47:01,274 - root - INFO - Epoch 27, train loss: 283.6188, val loss: 283.4257
2024-06-01 20:47:03,922 - root - INFO - Epoch 28, train loss: 283.9069, val loss: 282.8028
2024-06-01 20:47:06,480 - root - INFO - Epoch 29, train loss: 283.3519, val loss: 282.9074
2024-06-01 20:47:08,990 - root - INFO - Epoch 30, train loss: 283.4861, val loss: 284.2494
2024-06-01 20:47:11,563 - root - INFO - Epoch 31, train loss: 283.4162, val loss: 284.1725
2024-06-01 20:47:14,161 - root - INFO - Epoch 32, train loss: 283.9792, val loss: 283.1567
2024-06-01 20:47:16,730 - root - INFO - Epoch 33, train loss: 283.3526, val loss: 283.5946
2024-06-01 20:47:19,249 - root - INFO - Epoch 34, train loss: 283.2888, val loss: 282.9632
2024-06-01 20:47:21,903 - root - INFO - Epoch 35, train loss: 282.7674, val loss: 283.9859
2024-06-01 20:47:24,481 - root - INFO - Epoch 36, train loss: 283.0972, val loss: 283.5809
2024-06-01 20:47:27,025 - root - INFO - Epoch 37, train loss: 283.1465, val loss: 283.6377
2024-06-01 20:47:29,514 - root - INFO - Epoch 38, train loss: 283.1486, val loss: 283.7087
2024-06-01 20:47:32,104 - root - INFO - Epoch 39, train loss: 283.1171, val loss: 283.1224
2024-06-01 20:47:34,657 - root - INFO - Epoch 40, train loss: 283.1108, val loss: 283.1898
2024-06-01 20:47:37,314 - root - INFO - Epoch 41, train loss: 282.9919, val loss: 282.9189
2024-06-01 20:47:39,874 - root - INFO - Epoch 42, train loss: 282.6431, val loss: 283.1038
2024-06-01 20:47:42,435 - root - INFO - Epoch 43, train loss: 282.7517, val loss: 283.7464
2024-06-01 20:47:45,051 - root - INFO - Epoch 44, train loss: 282.4168, val loss: 283.1638
2024-06-01 20:47:47,640 - root - INFO - Epoch 45, train loss: 282.3893, val loss: 283.4889
2024-06-01 20:47:50,212 - root - INFO - Epoch 46, train loss: 282.4067, val loss: 283.0451
2024-06-01 20:47:52,843 - root - INFO - Epoch 47, train loss: 282.2625, val loss: 283.3341
2024-06-01 20:47:55,434 - root - INFO - Epoch 48, train loss: 282.0584, val loss: 283.5653
2024-06-01 20:47:57,966 - root - INFO - Epoch 49, train loss: 282.0992, val loss: 283.2435
2024-06-01 20:48:00,564 - root - INFO - Epoch 50, train loss: 282.0449, val loss: 283.2548
2024-06-01 20:50:14,197 - root - INFO - % of variation before training: 223.67
2024-06-01 20:50:14,198 - root - INFO - % of variation after training: 99.3
2024-06-01 20:50:14,198 - root - INFO - % of variation before training: 217.19
2024-06-01 20:50:14,199 - root - INFO - % of variation after training: 100.22
rs: 463373
2024-06-01 20:45:50,086 - root - INFO - Optimizer: RMSprop
2024-06-01 20:45:52,846 - root - INFO - Epoch 1, train loss: 296.3920, val loss: 287.3775
2024-06-01 20:45:55,704 - root - INFO - Epoch 2, train loss: 286.1608, val loss: 288.5585
2024-06-01 20:45:58,570 - root - INFO - Epoch 3, train loss: 286.4500, val loss: 286.7316
2024-06-01 20:46:01,202 - root - INFO - Epoch 4, train loss: 286.3061, val loss: 282.0581
2024-06-01 20:46:03,821 - root - INFO - Epoch 5, train loss: 285.8744, val loss: 284.3857
2024-06-01 20:46:06,457 - root - INFO - Epoch 6, train loss: 285.2371, val loss: 283.2864
2024-06-01 20:46:09,257 - root - INFO - Epoch 7, train loss: 285.7056, val loss: 284.5220
2024-06-01 20:46:12,163 - root - INFO - Epoch 8, train loss: 285.5517, val loss: 284.7376
2024-06-01 20:46:14,805 - root - INFO - Epoch 9, train loss: 284.4569, val loss: 285.1309
2024-06-01 20:46:17,521 - root - INFO - Epoch 10, train loss: 285.4274, val loss: 285.7804
2024-06-01 20:46:20,128 - root - INFO - Epoch 11, train loss: 285.1172, val loss: 284.2090
2024-06-01 20:46:22,742 - root - INFO - Epoch 12, train loss: 285.2431, val loss: 283.7445
2024-06-01 20:46:25,350 - root - INFO - Epoch 13, train loss: 284.7354, val loss: 283.9046
2024-06-01 20:46:27,881 - root - INFO - Epoch 14, train loss: 284.4495, val loss: 284.6602
2024-06-01 20:46:30,438 - root - INFO - Epoch 15, train loss: 284.7138, val loss: 283.0985
2024-06-01 20:46:33,141 - root - INFO - Epoch 16, train loss: 284.6518, val loss: 283.4829
2024-06-01 20:46:35,684 - root - INFO - Epoch 17, train loss: 284.3187, val loss: 287.2188
2024-06-01 20:46:38,249 - root - INFO - Epoch 18, train loss: 284.5894, val loss: 283.9859
2024-06-01 20:46:40,874 - root - INFO - Epoch 19, train loss: 284.7243, val loss: 284.1778
2024-06-01 20:46:43,398 - root - INFO - Epoch 20, train loss: 284.1900, val loss: 283.7112
2024-06-01 20:46:46,061 - root - INFO - Epoch 21, train loss: 284.1132, val loss: 285.5307
2024-06-01 20:46:48,586 - root - INFO - Epoch 22, train loss: 284.1733, val loss: 284.3941
2024-06-01 20:46:51,114 - root - INFO - Epoch 23, train loss: 284.1034, val loss: 284.1270
2024-06-01 20:46:53,690 - root - INFO - Epoch 24, train loss: 283.7132, val loss: 283.5032
2024-06-01 20:46:56,230 - root - INFO - Epoch 25, train loss: 283.5927, val loss: 282.8844
2024-06-01 20:46:58,695 - root - INFO - Epoch 26, train loss: 283.8695, val loss: 283.1343
2024-06-01 20:47:01,274 - root - INFO - Epoch 27, train loss: 283.6188, val loss: 283.4257
2024-06-01 20:47:03,922 - root - INFO - Epoch 28, train loss: 283.9069, val loss: 282.8028
2024-06-01 20:47:06,480 - root - INFO - Epoch 29, train loss: 283.3519, val loss: 282.9074
2024-06-01 20:47:08,990 - root - INFO - Epoch 30, train loss: 283.4861, val loss: 284.2494
2024-06-01 20:47:11,563 - root - INFO - Epoch 31, train loss: 283.4162, val loss: 284.1725
2024-06-01 20:47:14,161 - root - INFO - Epoch 32, train loss: 283.9792, val loss: 283.1567
2024-06-01 20:47:16,730 - root - INFO - Epoch 33, train loss: 283.3526, val loss: 283.5946
2024-06-01 20:47:19,249 - root - INFO - Epoch 34, train loss: 283.2888, val loss: 282.9632
2024-06-01 20:47:21,903 - root - INFO - Epoch 35, train loss: 282.7674, val loss: 283.9859
2024-06-01 20:47:24,481 - root - INFO - Epoch 36, train loss: 283.0972, val loss: 283.5809
2024-06-01 20:47:27,025 - root - INFO - Epoch 37, train loss: 283.1465, val loss: 283.6377
2024-06-01 20:47:29,514 - root - INFO - Epoch 38, train loss: 283.1486, val loss: 283.7087
2024-06-01 20:47:32,104 - root - INFO - Epoch 39, train loss: 283.1171, val loss: 283.1224
2024-06-01 20:47:34,657 - root - INFO - Epoch 40, train loss: 283.1108, val loss: 283.1898
2024-06-01 20:47:37,314 - root - INFO - Epoch 41, train loss: 282.9919, val loss: 282.9189
2024-06-01 20:47:39,874 - root - INFO - Epoch 42, train loss: 282.6431, val loss: 283.1038
2024-06-01 20:47:42,435 - root - INFO - Epoch 43, train loss: 282.7517, val loss: 283.7464
2024-06-01 20:47:45,051 - root - INFO - Epoch 44, train loss: 282.4168, val loss: 283.1638
2024-06-01 20:47:47,640 - root - INFO - Epoch 45, train loss: 282.3893, val loss: 283.4889
2024-06-01 20:47:50,212 - root - INFO - Epoch 46, train loss: 282.4067, val loss: 283.0451
2024-06-01 20:47:52,843 - root - INFO - Epoch 47, train loss: 282.2625, val loss: 283.3341
2024-06-01 20:47:55,434 - root - INFO - Epoch 48, train loss: 282.0584, val loss: 283.5653
2024-06-01 20:47:57,966 - root - INFO - Epoch 49, train loss: 282.0992, val loss: 283.2435
2024-06-01 20:48:00,564 - root - INFO - Epoch 50, train loss: 282.0449, val loss: 283.2548
2024-06-01 20:50:14,197 - root - INFO - % of variation before training: 223.67
2024-06-01 20:50:14,198 - root - INFO - % of variation after training: 99.3
2024-06-01 20:50:14,198 - root - INFO - % of variation before training: 217.19
2024-06-01 20:50:14,199 - root - INFO - % of variation after training: 100.22
                                                                                     2024-06-01 20:45:46,364 - root - INFO - N_EPOCH: 50
2024-06-01 20:45:46,365 - root - INFO - LEARNING_RATE: 8e-05
2024-06-01 20:45:46,366 - root - INFO - HIDDEN_LAYER: 28
2024-06-01 20:45:46,366 - root - INFO - HIDDEN_WIDTH: 128
2024-06-01 20:45:46,366 - root - INFO - EXPERIMENT_NAME: exp_put_10_gen
2024-06-01 20:45:46,366 - root - INFO - Model type: AmericanPut_gated3
2024-06-01 20:45:47,599 - root - INFO - train set size: (8000, 9)
2024-06-01 20:45:47,600 - root - INFO - test set size: (2000, 9)
2024-06-01 20:45:47,601 - root - INFO - Initial MSE train: 636.6559, Initial MSE val: 613.5619
2024-06-01 20:45:49,172 - root - INFO - Total number of learnable parameters: 463373
2024-06-01 20:45:50,086 - root - INFO - Optimizer: RMSprop
2024-06-01 20:45:52,846 - root - INFO - Epoch 1, train loss: 296.3920, val loss: 287.3775
2024-06-01 20:45:55,704 - root - INFO - Epoch 2, train loss: 286.1608, val loss: 288.5585
2024-06-01 20:45:58,570 - root - INFO - Epoch 3, train loss: 286.4500, val loss: 286.7316
2024-06-01 20:46:01,202 - root - INFO - Epoch 4, train loss: 286.3061, val loss: 282.0581
2024-06-01 20:46:03,821 - root - INFO - Epoch 5, train loss: 285.8744, val loss: 284.3857
2024-06-01 20:46:06,457 - root - INFO - Epoch 6, train loss: 285.2371, val loss: 283.2864
2024-06-01 20:46:09,257 - root - INFO - Epoch 7, train loss: 285.7056, val loss: 284.5220
2024-06-01 20:46:12,163 - root - INFO - Epoch 8, train loss: 285.5517, val loss: 284.7376
2024-06-01 20:46:14,805 - root - INFO - Epoch 9, train loss: 284.4569, val loss: 285.1309
2024-06-01 20:46:17,521 - root - INFO - Epoch 10, train loss: 285.4274, val loss: 285.7804
2024-06-01 20:46:20,128 - root - INFO - Epoch 11, train loss: 285.1172, val loss: 284.2090
2024-06-01 20:46:22,742 - root - INFO - Epoch 12, train loss: 285.2431, val loss: 283.7445
2024-06-01 20:46:25,350 - root - INFO - Epoch 13, train loss: 284.7354, val loss: 283.9046
2024-06-01 20:46:27,881 - root - INFO - Epoch 14, train loss: 284.4495, val loss: 284.6602
2024-06-01 20:46:30,438 - root - INFO - Epoch 15, train loss: 284.7138, val loss: 283.0985
2024-06-01 20:46:33,141 - root - INFO - Epoch 16, train loss: 284.6518, val loss: 283.4829
2024-06-01 20:46:35,684 - root - INFO - Epoch 17, train loss: 284.3187, val loss: 287.2188
2024-06-01 20:46:38,249 - root - INFO - Epoch 18, train loss: 284.5894, val loss: 283.9859
2024-06-01 20:46:40,874 - root - INFO - Epoch 19, train loss: 284.7243, val loss: 284.1778
2024-06-01 20:46:43,398 - root - INFO - Epoch 20, train loss: 284.1900, val loss: 283.7112
2024-06-01 20:46:46,061 - root - INFO - Epoch 21, train loss: 284.1132, val loss: 285.5307
2024-06-01 20:46:48,586 - root - INFO - Epoch 22, train loss: 284.1733, val loss: 284.3941
2024-06-01 20:46:51,114 - root - INFO - Epoch 23, train loss: 284.1034, val loss: 284.1270
2024-06-01 20:46:53,690 - root - INFO - Epoch 24, train loss: 283.7132, val loss: 283.5032
2024-06-01 20:46:56,230 - root - INFO - Epoch 25, train loss: 283.5927, val loss: 282.8844
2024-06-01 20:46:58,695 - root - INFO - Epoch 26, train loss: 283.8695, val loss: 283.1343
2024-06-01 20:47:01,274 - root - INFO - Epoch 27, train loss: 283.6188, val loss: 283.4257
2024-06-01 20:47:03,922 - root - INFO - Epoch 28, train loss: 283.9069, val loss: 282.8028
2024-06-01 20:47:06,480 - root - INFO - Epoch 29, train loss: 283.3519, val loss: 282.9074
2024-06-01 20:47:08,990 - root - INFO - Epoch 30, train loss: 283.4861, val loss: 284.2494
2024-06-01 20:47:11,563 - root - INFO - Epoch 31, train loss: 283.4162, val loss: 284.1725
2024-06-01 20:47:14,161 - root - INFO - Epoch 32, train loss: 283.9792, val loss: 283.1567
2024-06-01 20:47:16,730 - root - INFO - Epoch 33, train loss: 283.3526, val loss: 283.5946
2024-06-01 20:47:19,249 - root - INFO - Epoch 34, train loss: 283.2888, val loss: 282.9632
2024-06-01 20:47:21,903 - root - INFO - Epoch 35, train loss: 282.7674, val loss: 283.9859
2024-06-01 20:47:24,481 - root - INFO - Epoch 36, train loss: 283.0972, val loss: 283.5809
2024-06-01 20:47:27,025 - root - INFO - Epoch 37, train loss: 283.1465, val loss: 283.6377
2024-06-01 20:47:29,514 - root - INFO - Epoch 38, train loss: 283.1486, val loss: 283.7087
2024-06-01 20:47:32,104 - root - INFO - Epoch 39, train loss: 283.1171, val loss: 283.1224
2024-06-01 20:47:34,657 - root - INFO - Epoch 40, train loss: 283.1108, val loss: 283.1898
2024-06-01 20:47:37,314 - root - INFO - Epoch 41, train loss: 282.9919, val loss: 282.9189
2024-06-01 20:47:39,874 - root - INFO - Epoch 42, train loss: 282.6431, val loss: 283.1038
2024-06-01 20:47:42,435 - root - INFO - Epoch 43, train loss: 282.7517, val loss: 283.7464
2024-06-01 20:47:45,051 - root - INFO - Epoch 44, train loss: 282.4168, val loss: 283.1638
2024-06-01 20:47:47,640 - root - INFO - Epoch 45, train loss: 282.3893, val loss: 283.4889
2024-06-01 20:47:50,212 - root - INFO - Epoch 46, train loss: 282.4067, val loss: 283.0451
2024-06-01 20:47:52,843 - root - INFO - Epoch 47, train loss: 282.2625, val loss: 283.3341
2024-06-01 20:47:55,434 - root - INFO - Epoch 48, train loss: 282.0584, val loss: 283.5653
2024-06-01 20:47:57,966 - root - INFO - Epoch 49, train loss: 282.0992, val loss: 283.2435
2024-06-01 20:48:00,564 - root - INFO - Epoch 50, train loss: 282.0449, val loss: 283.2548
2024-06-01 20:50:14,197 - root - INFO - % of variation before training: 223.67
2024-06-01 20:50:14,198 - root - INFO - % of variation after training: 99.3
2024-06-01 20:50:14,198 - root - INFO - % of variation before training: 217.19
2024-06-01 20:50:14,199 - root - INFO - % of variation after training: 100.22
0:14,199 - root - INFO - % of variation after training: 100.22
