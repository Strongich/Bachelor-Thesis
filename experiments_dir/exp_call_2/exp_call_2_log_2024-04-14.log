2024-04-14 18:31:10,110 - root - INFO - Running on device=cuda
2024-04-14 18:31:10,473 - root - INFO - N_EPOCH: 20
2024-04-14 18:31:10,473 - root - INFO - LEARNING_RATE: 4e-07
2024-04-14 18:31:10,473 - root - INFO - HIDDEN_LAYER: 15
2024-04-14 18:31:10,473 - root - INFO - HIDDEN_WIDTH: 128
2024-04-14 18:31:10,473 - root - INFO - EXPERIMENT_NAME: exp_call_2
2024-04-14 18:31:10,473 - root - INFO - Model type: Call_2
2024-04-14 18:31:10,898 - root - INFO - Initial MSE train: 51.9329, Initial MSE val: 31.345
2024-04-14 18:31:12,599 - root - INFO - Total number of learnable parameters: 319115
2024-04-14 18:31:14,259 - root - INFO - Optimizer: SGD
2024-04-14 18:31:15,427 - root - INFO - Epoch 1, train loss: 49.8708, test loss: 39.6513
2024-04-14 18:31:16,450 - root - INFO - Epoch 2, train loss: 49.4566, test loss: 32.0233
2024-04-14 18:31:17,465 - root - INFO - Epoch 3, train loss: 49.3007, test loss: 28.7942
2024-04-14 18:31:18,477 - root - INFO - Epoch 4, train loss: 54.9704, test loss: 35.5410
2024-04-14 18:31:19,651 - root - INFO - Epoch 5, train loss: 48.8004, test loss: 39.4319
2024-04-14 18:31:20,645 - root - INFO - Epoch 6, train loss: 49.2023, test loss: 65.9483
2024-04-14 18:31:21,610 - root - INFO - Epoch 7, train loss: 48.4199, test loss: 32.2719
2024-04-14 18:31:22,670 - root - INFO - Epoch 8, train loss: 48.3911, test loss: 29.4985
2024-04-14 18:31:23,657 - root - INFO - Epoch 9, train loss: 49.5758, test loss: 84.0419
2024-04-14 18:31:24,691 - root - INFO - Epoch 10, train loss: 47.5095, test loss: 34.3592
2024-04-14 18:31:25,650 - root - INFO - Epoch 11, train loss: 47.3353, test loss: 30.6953
2024-04-14 18:31:26,656 - root - INFO - Epoch 12, train loss: 47.0837, test loss: 49.5007
2024-04-14 18:31:27,665 - root - INFO - Epoch 13, train loss: 51.7804, test loss: 29.1530
2024-04-14 18:31:28,655 - root - INFO - Epoch 14, train loss: 47.0542, test loss: 29.4624
2024-04-14 18:31:29,652 - root - INFO - Epoch 15, train loss: 46.6476, test loss: 71.1714
2024-04-14 18:31:30,735 - root - INFO - Epoch 16, train loss: 46.5280, test loss: 98.0626
2024-04-14 18:31:31,752 - root - INFO - Epoch 17, train loss: 47.1937, test loss: 27.5844
2024-04-14 18:31:32,771 - root - INFO - Epoch 18, train loss: 46.1833, test loss: 208.8087
2024-04-14 18:31:33,767 - root - INFO - Epoch 19, train loss: 45.7417, test loss: 27.0862
2024-04-14 18:31:34,794 - root - INFO - Epoch 20, train loss: 45.8412, test loss: 27.1804
2024-04-14 18:31:34,794 - root - INFO - Optimizer: RMSprop
2024-04-14 18:31:35,935 - root - INFO - Epoch 1, train loss: 45.3218, test loss: 34.4534
2024-04-14 18:31:37,079 - root - INFO - Epoch 2, train loss: 46.6649, test loss: 25.7914
2024-04-14 18:31:38,114 - root - INFO - Epoch 3, train loss: 45.2337, test loss: 30.1083
2024-04-14 18:31:39,120 - root - INFO - Epoch 4, train loss: 45.0151, test loss: 40.4543
2024-04-14 18:31:40,186 - root - INFO - Epoch 5, train loss: 44.9496, test loss: 26.4677
2024-04-14 18:31:41,186 - root - INFO - Epoch 6, train loss: 44.6227, test loss: 27.0342
2024-04-14 18:31:42,205 - root - INFO - Epoch 7, train loss: 46.1664, test loss: 25.9358
2024-04-14 18:31:43,223 - root - INFO - Epoch 8, train loss: 44.5333, test loss: 24.8115
2024-04-14 18:31:44,250 - root - INFO - Epoch 9, train loss: 44.6120, test loss: 32.2926
2024-04-14 18:31:45,318 - root - INFO - Epoch 10, train loss: 44.4792, test loss: 29.0230
2024-04-14 18:31:46,354 - root - INFO - Epoch 11, train loss: 44.5982, test loss: 28.1698
2024-04-14 18:31:47,431 - root - INFO - Epoch 12, train loss: 44.2227, test loss: 46.4617
2024-04-14 18:31:48,462 - root - INFO - Epoch 13, train loss: 44.2795, test loss: 27.0951
2024-04-14 18:31:49,546 - root - INFO - Epoch 14, train loss: 43.8462, test loss: 25.1327
2024-04-14 18:31:50,533 - root - INFO - Epoch 15, train loss: 44.3904, test loss: 26.0335
2024-04-14 18:31:51,553 - root - INFO - Epoch 16, train loss: 44.1298, test loss: 24.7913
2024-04-14 18:31:52,634 - root - INFO - Epoch 17, train loss: 44.0725, test loss: 45.9322
2024-04-14 18:31:53,681 - root - INFO - Epoch 18, train loss: 43.6484, test loss: 27.7419
2024-04-14 18:31:54,708 - root - INFO - Epoch 19, train loss: 47.6519, test loss: 25.5567
2024-04-14 18:31:55,706 - root - INFO - Epoch 20, train loss: 43.2850, test loss: 29.3905
2024-04-14 18:31:55,707 - root - INFO - Optimizer: Adam
2024-04-14 18:31:56,794 - root - INFO - Epoch 1, train loss: 43.7019, test loss: 32.9335
2024-04-14 18:31:57,907 - root - INFO - Epoch 2, train loss: 43.2323, test loss: 29.6838
2024-04-14 18:31:58,976 - root - INFO - Epoch 3, train loss: 44.0661, test loss: 29.6425
2024-04-14 18:32:00,038 - root - INFO - Epoch 4, train loss: 43.1969, test loss: 24.2519
2024-04-14 18:32:01,103 - root - INFO - Epoch 5, train loss: 42.9953, test loss: 26.9367
2024-04-14 18:32:02,112 - root - INFO - Epoch 6, train loss: 43.4860, test loss: 23.5732
2024-04-14 18:32:03,206 - root - INFO - Epoch 7, train loss: 43.0144, test loss: 25.2305
2024-04-14 18:32:04,333 - root - INFO - Epoch 8, train loss: 43.5454, test loss: 24.9030
2024-04-14 18:32:05,431 - root - INFO - Epoch 9, train loss: 42.8254, test loss: 24.3313
2024-04-14 18:32:06,474 - root - INFO - Epoch 10, train loss: 43.1559, test loss: 23.2712
2024-04-14 18:32:07,531 - root - INFO - Epoch 11, train loss: 43.0042, test loss: 24.0886
2024-04-14 18:32:08,557 - root - INFO - Epoch 12, train loss: 42.6677, test loss: 23.3822
2024-04-14 18:32:09,646 - root - INFO - Epoch 13, train loss: 42.6457, test loss: 33.2747
2024-04-14 18:32:10,819 - root - INFO - Epoch 14, train loss: 42.6045, test loss: 23.1617
2024-04-14 18:32:11,890 - root - INFO - Epoch 15, train loss: 42.6917, test loss: 26.2793
2024-04-14 18:32:12,957 - root - INFO - Epoch 16, train loss: 42.5797, test loss: 24.4371
2024-04-14 18:32:14,050 - root - INFO - Epoch 17, train loss: 42.7766, test loss: 23.7754
2024-04-14 18:32:15,086 - root - INFO - Epoch 18, train loss: 42.9006, test loss: 23.6493
2024-04-14 18:32:16,210 - root - INFO - Epoch 19, train loss: 42.3540, test loss: 23.6441
2024-04-14 18:32:17,300 - root - INFO - Epoch 20, train loss: 42.4247, test loss: 25.7791
2024-04-14 18:32:17,300 - root - INFO - Optimizer: Adamax
2024-04-14 18:32:18,746 - root - INFO - Epoch 1, train loss: 42.5185, test loss: 25.4716
2024-04-14 18:32:20,107 - root - INFO - Epoch 2, train loss: 42.5408, test loss: 22.6479
2024-04-14 18:32:21,467 - root - INFO - Epoch 3, train loss: 42.5403, test loss: 22.9912
2024-04-14 18:32:22,863 - root - INFO - Epoch 4, train loss: 41.9807, test loss: 25.3096
2024-04-14 18:32:24,230 - root - INFO - Epoch 5, train loss: 42.2197, test loss: 24.9560
2024-04-14 18:32:25,589 - root - INFO - Epoch 6, train loss: 42.1918, test loss: 27.5589
2024-04-14 18:32:26,984 - root - INFO - Epoch 7, train loss: 42.2116, test loss: 23.5809
2024-04-14 18:32:28,370 - root - INFO - Epoch 8, train loss: 44.7315, test loss: 27.1027
2024-04-14 18:32:29,748 - root - INFO - Epoch 9, train loss: 42.2087, test loss: 22.6777
2024-04-14 18:32:31,165 - root - INFO - Epoch 10, train loss: 45.9676, test loss: 24.8785
2024-04-14 18:32:32,544 - root - INFO - Epoch 11, train loss: 42.0753, test loss: 24.5350
2024-04-14 18:32:33,997 - root - INFO - Epoch 12, train loss: 42.1051, test loss: 27.8105
2024-04-14 18:32:35,399 - root - INFO - Epoch 13, train loss: 42.2371, test loss: 23.2416
2024-04-14 18:32:36,811 - root - INFO - Epoch 14, train loss: 42.0617, test loss: 25.2687
2024-04-14 18:32:38,173 - root - INFO - Epoch 15, train loss: 42.7173, test loss: 24.0586
2024-04-14 18:32:39,546 - root - INFO - Epoch 16, train loss: 42.1426, test loss: 23.8641
2024-04-14 18:32:40,867 - root - INFO - Epoch 17, train loss: 42.4519, test loss: 24.4776
2024-04-14 18:32:42,376 - root - INFO - Epoch 18, train loss: 42.7414, test loss: 23.7875
2024-04-14 18:32:43,744 - root - INFO - Epoch 19, train loss: 42.0662, test loss: 24.7763
2024-04-14 18:32:45,117 - root - INFO - Epoch 20, train loss: 42.2268, test loss: 23.0446
2024-04-14 18:34:31,243 - root - INFO - N_EPOCH: 30
2024-04-14 18:34:31,243 - root - INFO - LEARNING_RATE: 4e-07
2024-04-14 18:34:31,243 - root - INFO - HIDDEN_LAYER: 20
2024-04-14 18:34:31,243 - root - INFO - HIDDEN_WIDTH: 256
2024-04-14 18:34:31,244 - root - INFO - EXPERIMENT_NAME: exp_call_3_final
2024-04-14 18:34:31,244 - root - INFO - Model type: Call_2
2024-04-14 18:34:38,005 - root - INFO - train set size: (178573, 12)
2024-04-14 18:34:38,005 - root - INFO - test set size: (44644, 12)
2024-04-14 18:34:38,007 - root - INFO - Initial MSE train: 42.5196, Initial MSE val: 40.2708
2024-04-14 18:35:05,969 - root - INFO - Total number of learnable parameters: 1426699
2024-04-14 18:35:05,987 - root - INFO - Total number of learnable parameters: 1426699
2024-04-14 18:35:21,486 - root - INFO - Optimizer: Adamax
2024-04-14 18:35:50,880 - root - INFO - Epoch 1, train loss: 53.7434, test loss: 387.8287
2024-04-14 18:36:19,056 - root - INFO - Epoch 2, train loss: 53.6750, test loss: 419.2363
2024-04-14 18:36:46,658 - root - INFO - Epoch 3, train loss: 53.6499, test loss: 909.0248
2024-04-14 18:37:13,872 - root - INFO - Epoch 4, train loss: 53.6571, test loss: 992.2169
2024-04-14 18:37:41,377 - root - INFO - Epoch 5, train loss: 53.6839, test loss: 2294.2037
2024-04-14 18:38:08,997 - root - INFO - Epoch 6, train loss: 53.6636, test loss: 2367.4621
2024-04-14 18:38:36,440 - root - INFO - Epoch 7, train loss: 53.6582, test loss: 152.6268
2024-04-14 18:39:03,818 - root - INFO - Epoch 8, train loss: 53.6709, test loss: 142.9207
2024-04-14 18:39:31,416 - root - INFO - Epoch 9, train loss: 53.6590, test loss: 2486.3030
2024-04-14 18:39:58,736 - root - INFO - Epoch 10, train loss: 53.6850, test loss: 692.9388
2024-04-14 18:40:25,669 - root - INFO - Epoch 11, train loss: 53.6334, test loss: 643.0713
2024-04-14 18:40:53,203 - root - INFO - Epoch 12, train loss: 53.6430, test loss: 163.5307
2024-04-14 18:41:20,609 - root - INFO - Epoch 13, train loss: 53.6368, test loss: 155.9182
2024-04-14 18:41:47,946 - root - INFO - Epoch 14, train loss: 53.6648, test loss: 4083.4204
2024-04-14 18:42:15,156 - root - INFO - Epoch 15, train loss: 53.6508, test loss: 908.5866
2024-04-14 18:42:42,758 - root - INFO - Epoch 16, train loss: 53.6926, test loss: 27621.1862
2024-04-14 18:43:10,135 - root - INFO - Epoch 17, train loss: 53.6458, test loss: 589.7043
2024-04-14 18:43:37,616 - root - INFO - Epoch 18, train loss: 53.7978, test loss: 164.6072
2024-04-14 18:44:05,203 - root - INFO - Epoch 19, train loss: 53.7281, test loss: 102.0136
2024-04-14 18:44:32,775 - root - INFO - Epoch 20, train loss: 53.6865, test loss: 3079.7139
2024-04-14 18:45:00,063 - root - INFO - Epoch 21, train loss: 53.6605, test loss: 101.7256
2024-04-14 18:45:27,254 - root - INFO - Epoch 22, train loss: 53.6566, test loss: 718.7338
2024-04-14 18:45:54,427 - root - INFO - Epoch 23, train loss: 53.6969, test loss: 9750.0523
2024-04-14 18:46:22,080 - root - INFO - Epoch 24, train loss: 53.6609, test loss: 242.1091
2024-04-14 18:46:49,367 - root - INFO - Epoch 25, train loss: 53.7008, test loss: 199051.7107
2024-04-14 18:47:16,639 - root - INFO - Epoch 26, train loss: 53.6485, test loss: 182.4106
2024-04-14 18:47:44,109 - root - INFO - Epoch 27, train loss: 53.6370, test loss: 53.7076
2024-04-14 18:48:10,948 - root - INFO - Epoch 28, train loss: 53.6910, test loss: 96.6992
2024-04-14 18:48:38,175 - root - INFO - Epoch 29, train loss: 53.6537, test loss: 76.0594
2024-04-14 18:49:05,722 - root - INFO - Epoch 30, train loss: 53.6881, test loss: 578.6624
2024-04-14 18:59:22,952 - root - INFO - Total number of learnable parameters: 1426699
2024-04-14 18:59:30,979 - root - INFO - Total number of learnable parameters: 1426699
2024-04-14 18:59:30,996 - root - INFO - Total number of learnable parameters: 1426699
